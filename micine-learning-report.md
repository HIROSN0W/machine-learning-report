# 機械学習
<div style="text-align: right;">
<h2>3I24　中川 寛之</h2>
</div>  

## 目的
- 機械学習とはどのようなものかを知る。
- sklearnモジュールにあるランダムフォレストを使用して入力データから次に出現するクラスを予想する。
- モデル生成のパラメータを変えていき、学習内容と学習量の変化を確認する。
- 学習結果を可視化して、人間では導きづらいであろう判定基準(学習によって作られた分類器)などを確認する。
## 学習に使用したデータの概要
```
num3_train.csv :　今まででた宝くじの抽選番号
num3_train_h.csv :　num3_train.csvの100の位
num3_train_t.csv :　num3_train.csvの 10の位
num3_train_o.csv :　num3_train.csvの  1の位
num3_test.csv :　最新の宝くじの抽選番号
```
## 実験１：データの準備とモデルの生成
>使用したcsvのファイル名と出力された決定木の画像ファイルを示す

![出力された決定木](exp1.png)

>決定木の文字がめちゃくちゃになっている理由  

三桁の自然数で作れる値の数は100通りであり全通りを試しているため、このようにめちゃくちゃになっている。  

> 出力された学習スコアとテストスコア

```
0       884
1        98
2       475
3       335
4       224
       ... 
6507    792
6508    592
6509    105
6510    194
6511    988
Name: nxt, Length: 6512, dtype: int64
Train score: 1.0
Test score: 0.006653019447287615
```  

## 実験２：クラス分類規模の縮小
>使用したcsvファイル名と出力された決定木の画像ファイル

### <num3_train_h.csv>
![出力された決定木 h](exp2_h.png)
- 学習スコアとテストスコア
```
0       8
1       0
2       4
3       3
4       2
       ..
6507    7
6508    5
6509    1
6510    1
6511    9
Name: nxt, Length: 6512, dtype: int64
Train score: 1.0
Test score: 0.11258955987717502
```  
---
### <num3_train_t.csv>
![出力された決定木 t](exp2_t.png)
- 学習スコアとテストスコア
```
0       8
1       9
2       7
3       3
4       2
       ..
6507    9
6508    9
6509    0
6510    9
6511    8
Name: nxt, Length: 6512, dtype: int64
Train score: 1.0
Test score: 0.11924257932446264
```
---
### <num3_train_o.csv>
![出力された決定木 o](exp2_o.png)

- 学習スコアとテストスコア
```
0       4
1       8
2       5
3       5
4       4
       ..
6507    2
6508    2
6509    5
6510    4
6511    8
Name: nxt, Length: 6512, dtype: int64
Train score: 1.0
Test score: 0.11566018423746162
```
>実験１と何が変化したか、 またその理由

実験１と比べて、Test scoreが高くなった。  
理由は以下のようなことが考えられる。  

- 計算コストの削減:  
       - タスク2クラスの数が多いと、計算コストが増える。そのためクラスの数を減らすことで、計算コストが削減することで、より効率的に学習ができる。  
- ノイズの減少:  
       - クラス数が多いと、データに含まれるノイズが増える可能性があります。クラス数を減らすことで、ノイズが減少し、モデルの精度が向上します。

## 実験３：学習モデルからの予測  

> コンソールからの出力
```
[0]
[7]
[8]
```
## 実験４：パラメータの変更  

> 設定したパラメーター

```python
forest = RandomForestClassifier(n_estimators=150, max_depth=None)
```

> 出力された学習スコアとテストスコア


```
<num4_train_h.csv>

0       8
1       9
2       7
3       3
4       2
       ..
6507    9
6508    9
6509    0
6510    9
6511    8
Name: nxt, Length: 6512, dtype: int64
Train score: 1.0
Test score: 0.11156601842374617
```
---
```
<num4_train_t.csv>

0       8
1       9
2       7
3       3
4       2
       ..
6507    9
6508    9
6509    0
6510    9
6511    8
Name: nxt, Length: 6512, dtype: int64
Train score: 1.0
Test score: 0.11412487205731832
```
---
```
<num4_train_o.csv>

0       4
1       8
2       5
3       5
4       4
       ..
6507    2
6508    2
6509    5
6510    4
6511    8
Name: nxt, Length: 6512, dtype: int64
Train score: 1.0
Test score: 0.1202661207778915
```
> 出力された決定木

![上がったやつ](exp4_o.png)

> パラメーター変更により得られた予測結果
```
[0]
[1]
[8]
```

## 今回の実験で理解したこと、理解できていないこと
今回の実験で理解したところは機械学習ではデータがどれだけ重要であり、適切に処理されていないデータと処理を加えてたデータでモデルの性能に影響を与えるかを実感した。データのクリーニングや変換を行うことで、モデルの精度が劇的に向上することを経験することができた。
## ランダムフォレストによる宝くじ予想で想定される・考慮すべき問題点
まずランダムフォレストのステップを整理すると、  
1. 元データからランダムにデータをブートストラップでサンプリングし、Nグループ分データグループを作成。   
2. Nグループそれぞれで決定木モデルを作成。
3. Nグループそれぞれの決定木モデルで予測を一旦行う。  
4. Nグループの多数決(回帰は平均)をとり、最終予測を行う。  

まず第一に宝くじというのは、数字をランダムに表示しているわけで、(n桁の数字とすると) 10^n通りの数が出る確率が同様に確かなのでstep3の予測というのは正しく行うことができことが問題点(実際には収束することがないので、多少の偏りがあるだろうが、、、)。  
賭け事というのは勝つ確率が高いときにだけするのが定石であり賭け事をしないというのが一番の勝利。